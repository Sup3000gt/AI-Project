{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e764cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.metrics import AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a26202",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = r\"C:\\\\Users\\\\xinga\\\\OneDrive\\\\文档\\\\GitHub\\\\AI-Project\\\\CSC547 Final Project\\\\brain_tumor_dataset\" \n",
    "# Directory of root folder of dataset (split into Train and Test Folders within that directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9e73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dir = \"C:\\\\Users\\\\xinga\\\\OneDrive\\\\文档\\\\GitHub\\\\AI-Project\\\\CSC547 Final Project\\\\brain_tumor_dataset\\\\train\"\n",
    "test_dataset_dir  = \"C:\\\\Users\\\\xinga\\\\OneDrive\\\\文档\\\\GitHub\\\\AI-Project\\\\CSC547 Final Project\\\\brain_tumor_dataset\\\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b7ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the images as they are read in\n",
    "# note: you can add other data augmentation functions to the ImageDataGenerator if you want\n",
    "# Here is a page with what you can add to the ImageDataGenerator: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "train = ImageDataGenerator(rescale = 1/255)\n",
    "test = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b2d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202 images belonging to 2 classes.\n",
      "Found 51 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a stream of images, resized to 256x256, grouped into batches of size 8, and classified into 2 categories\n",
    "train_dataset = train.flow_from_directory(train_dataset_dir, target_size = (256,256), batch_size=8, class_mode='binary')\n",
    "test_dataset  = test.flow_from_directory(test_dataset_dir, target_size = (256,256), batch_size=8, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00af6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # create a new sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3cae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 2D convolution layer with 16 features, a 3x3 filter size, relu activation, and padding\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding = 'same', input_shape=(256,256,3)))\n",
    "# Add a Max Pool layer with a 2x2 pooling window\n",
    "model.add(MaxPool2D(2, 2))\n",
    "\n",
    "# These are the same as above, except the convolution has 32 features\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2157e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the same as above, except the convolution has 64 features\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(2, 2))\n",
    "\n",
    "# These are the same as above, except the convolution has 128 features\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f2e6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten into a single vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer to 128 nodes (to extract relationships between features)\n",
    "model.add(Dense(128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f76169ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Dense layer with 1 node and \"sigmoid\" activation function to extract a binary prediction \n",
    "# (whether an image contains a tumor or not).\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dec4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using adam optimization, calculating loss using binary cross-entropy loss, and collect the metrics listed\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy', AUC(), TruePositives(), TrueNegatives(), FalsePositives(), FalseNegatives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96bead12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4194432   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,292,001\n",
      "Trainable params: 4,292,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print out a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a41715b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 12s 406ms/step - loss: 0.7258 - accuracy: 0.6782 - auc: 0.6940 - true_positives: 100.0000 - true_negatives: 37.0000 - false_positives: 41.0000 - false_negatives: 24.0000 - val_loss: 0.4252 - val_accuracy: 0.8824 - val_auc: 0.8927 - val_true_positives: 30.0000 - val_true_negatives: 15.0000 - val_false_positives: 5.0000 - val_false_negatives: 1.0000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 9s 347ms/step - loss: 0.5047 - accuracy: 0.7673 - auc: 0.8135 - true_positives: 108.0000 - true_negatives: 47.0000 - false_positives: 31.0000 - false_negatives: 16.0000 - val_loss: 0.4733 - val_accuracy: 0.8431 - val_auc: 0.8935 - val_true_positives: 28.0000 - val_true_negatives: 15.0000 - val_false_positives: 5.0000 - val_false_negatives: 3.0000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 8s 291ms/step - loss: 0.4086 - accuracy: 0.8416 - auc: 0.8849 - true_positives: 115.0000 - true_negatives: 55.0000 - false_positives: 23.0000 - false_negatives: 9.0000 - val_loss: 0.3934 - val_accuracy: 0.8824 - val_auc: 0.9040 - val_true_positives: 28.0000 - val_true_negatives: 17.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 8s 308ms/step - loss: 0.3480 - accuracy: 0.8663 - auc: 0.9167 - true_positives: 116.0000 - true_negatives: 59.0000 - false_positives: 19.0000 - false_negatives: 8.0000 - val_loss: 0.4766 - val_accuracy: 0.7647 - val_auc: 0.8710 - val_true_positives: 23.0000 - val_true_negatives: 16.0000 - val_false_positives: 4.0000 - val_false_negatives: 8.0000\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 7s 287ms/step - loss: 0.3456 - accuracy: 0.8465 - auc: 0.9254 - true_positives: 111.0000 - true_negatives: 60.0000 - false_positives: 18.0000 - false_negatives: 13.0000 - val_loss: 0.4937 - val_accuracy: 0.7451 - val_auc: 0.8935 - val_true_positives: 21.0000 - val_true_negatives: 17.0000 - val_false_positives: 3.0000 - val_false_negatives: 10.0000\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 8s 328ms/step - loss: 0.1628 - accuracy: 0.9406 - auc: 0.9843 - true_positives: 121.0000 - true_negatives: 69.0000 - false_positives: 9.0000 - false_negatives: 3.0000 - val_loss: 0.6137 - val_accuracy: 0.7843 - val_auc: 0.9161 - val_true_positives: 23.0000 - val_true_negatives: 17.0000 - val_false_positives: 3.0000 - val_false_negatives: 8.0000\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 8s 297ms/step - loss: 0.1154 - accuracy: 0.9554 - auc: 0.9903 - true_positives: 119.0000 - true_negatives: 74.0000 - false_positives: 4.0000 - false_negatives: 5.0000 - val_loss: 0.5660 - val_accuracy: 0.8431 - val_auc: 0.8798 - val_true_positives: 29.0000 - val_true_negatives: 14.0000 - val_false_positives: 6.0000 - val_false_negatives: 2.0000\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 7s 277ms/step - loss: 0.0711 - accuracy: 0.9703 - auc: 0.9981 - true_positives: 122.0000 - true_negatives: 74.0000 - false_positives: 4.0000 - false_negatives: 2.0000 - val_loss: 0.6225 - val_accuracy: 0.8235 - val_auc: 0.8879 - val_true_positives: 25.0000 - val_true_negatives: 17.0000 - val_false_positives: 3.0000 - val_false_negatives: 6.0000\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 7s 284ms/step - loss: 0.0235 - accuracy: 0.9950 - auc: 0.9999 - true_positives: 124.0000 - true_negatives: 77.0000 - false_positives: 1.0000 - false_negatives: 0.0000e+00 - val_loss: 1.2527 - val_accuracy: 0.7451 - val_auc: 0.8903 - val_true_positives: 20.0000 - val_true_negatives: 18.0000 - val_false_positives: 2.0000 - val_false_negatives: 11.0000\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 0.0243 - accuracy: 0.9950 - auc: 0.9994 - true_positives: 123.0000 - true_negatives: 78.0000 - false_positives: 0.0000e+00 - false_negatives: 1.0000 - val_loss: 1.0727 - val_accuracy: 0.7647 - val_auc: 0.8774 - val_true_positives: 21.0000 - val_true_negatives: 18.0000 - val_false_positives: 2.0000 - val_false_negatives: 10.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training dataset over 10 epochs, using the test dataset to validate the results\n",
    "history = model.fit(train_dataset, steps_per_epoch=len(train_dataset), epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47eceafa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25552\\3898635669.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = cv2.imread('C:\\\\Users\\\\alan\\\\AI Project\\\\CSC547 Final Project\\\\brain_tumor_dataset\\\\unseen data with brain tumor.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = cv2.resize(new_image, (256, 256))\n",
    "new_image = np.expand_dims(new_image, axis=0)\n",
    "new_image = new_image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fccfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(new_image)\n",
    "class_index = np.argmax(predictions)\n",
    "class_label = classes[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dac83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted class label:', class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f00c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02918c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy values\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805caba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss values\n",
    "plt.plot(loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec330b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
