{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b0f604",
   "metadata": {},
   "source": [
    "### Natural vs Machine Language\n",
    "\n",
    "Human language are called \"natural\" language. it is messy, ambiguous, chaotic, sprawling and constantly in flux.\n",
    "Machine language is highly structured and rigorous with syntax rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4c71061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TextVectorization\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0e1c3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"This movie is really bad\", \"I don't like this movie.\", \"The special effects were impressive but the story fell flat.\"\n",
    "         , \"The main character looks so cool.\", \"I really like the female character that die at the end.\", \"I couldn't even make it through this movie\"]\n",
    "labels = np.array([0,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e7831fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This movie is really bad',\n",
       " \"I don't like this movie.\",\n",
       " 'The special effects were impressive but the story fell flat.',\n",
       " 'The main character looks so cool.',\n",
       " 'I really like the female character that die at the end.',\n",
       " \"I couldn't even make it through this movie\"]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "94581b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "vectorizer = TextVectorization(max_tokens=10000, output_mode='tf_idf',standardize='lower_and_strip_punctuation',\n",
    "                               split='whitespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "429fd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4b432800",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "70a05315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3df298f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(SimpleRNN(64,input_shape=(max_len,1)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6083bfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d3be3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9a92f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.6969 - accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6377 - accuracy: 0.8333\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5833 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5335 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4878 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad96c02880>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, labels, batch_size=16, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "79b472e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [\"I was blown away by this movie!\", \"I wouldn't recommend this movie to anyone.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2834c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6975 - accuracy: 0.5000\n",
      "Test set accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "new_labels = np.array([1,0])\n",
    "new_X = vectorizer(new_texts)\n",
    "new_X = pad_sequences(new_X, maxlen=max_len)\n",
    "loss, accuracy = model.evaluate(new_X, new_labels)\n",
    "print(\"Test set accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf613f",
   "metadata": {},
   "source": [
    "TF-IDF\n",
    "\n",
    "terms = one key word that will affect the result (terrible,amazing)\n",
    "\n",
    "documentation = one sentence\n",
    "\n",
    "data = all our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4148f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b705e93",
   "metadata": {},
   "source": [
    "terms: whos TF-IDF score we want to compute\n",
    "\n",
    "document: the document in which the term appears\n",
    "\n",
    "dataset: list of documents that sre used to compute the document frequency of the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8308a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
