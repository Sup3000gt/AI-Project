{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b0f604",
   "metadata": {},
   "source": [
    "### Natural vs Machine Language\n",
    "\n",
    "Human language are called \"natural\" language. it is messy, ambiguous, chaotic, sprawling and constantly in flux.\n",
    "Machine language is highly structured and rigorous with syntax rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4c71061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TextVectorization\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0e1c3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"This movie is really bad\", \"I don't like this movie.\", \"The special effects were impressive but the story fell flat.\"\n",
    "         , \"The main character looks so cool.\", \"I really like the female character that die at the end.\", \"I couldn't even make it through this movie\"]\n",
    "labels = np.array([0,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e7831fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This movie is really bad',\n",
       " \"I don't like this movie.\",\n",
       " 'The special effects were impressive but the story fell flat.',\n",
       " 'The main character looks so cool.',\n",
       " 'I really like the female character that die at the end.',\n",
       " \"I couldn't even make it through this movie\"]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "94581b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "vectorizer = TextVectorization(max_tokens=10000, output_mode='int',standardize='lower_and_strip_punctuation',\n",
    "                               split='whitespace',output_sequence_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "429fd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4b432800",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "70a05315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3df298f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(max_len,)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6083bfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4, 19,  6, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 5, 27,  7,  3,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 2, 13, 26,  9, 20, 31,  2, 12, 23, 21,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 2, 16,  8, 17, 14, 30,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 5,  6,  7,  2, 22,  8, 11, 28, 33,  2, 25,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 5, 29, 24, 15, 18, 10,  3,  4,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d3be3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9a92f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.2360 - accuracy: 0.8333\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0774 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136e3ec6f70>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, labels, batch_size=16, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "79b472e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [\"I was blown away by this movie!\", \"I wouldn't recommend this movie to anyone.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2834c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x00000136E4FC40D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0236 - accuracy: 0.5000\n",
      "Test set accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "new_labels = np.array([1,0])\n",
    "new_X = vectorizer(new_texts)\n",
    "new_X = pad_sequences(new_X, maxlen=max_len)\n",
    "loss, accuracy = model.evaluate(new_X, new_labels)\n",
    "print(\"Test set accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291b5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
