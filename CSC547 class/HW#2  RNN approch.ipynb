{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d12eca2",
   "metadata": {},
   "source": [
    "#### Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4819232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4abef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'C:\\\\Users\\\\xinga\\\\OneDrive\\\\文档\\\\GitHub\\\\AI-Project\\\\dataset\\\\aclImdb\\\\train'\n",
    "val_dir = 'C:\\\\Users\\\\xinga\\\\OneDrive\\\\文档\\\\GitHub\\\\AI-Project\\\\dataset\\\\aclImdb\\\\test'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    class_names=['neg', 'pos'])\n",
    "\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    val_dir,\n",
    "    batch_size=batch_size,\n",
    "    class_names=['neg', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab969ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae8d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text vectorization layer\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=10000,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d030d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Fit the text vectorization layer to the training data\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d086eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the text vectorization layer to the data\n",
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d48620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the text vectorization layer to the training and validation data\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e91fa0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(None, 500), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7299027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=16))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Embedding(input_dim=10000, output_dim=16),\n",
    "#     SimpleRNN(16),\n",
    "#     layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Embedding(input_dim=10000, output_dim=64),\n",
    "#     layers.LSTM(64),\n",
    "#     layers.Dense(1, activation='sigmoid')\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d4456fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f879dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 433s 550ms/step - loss: 0.6933 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5051\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 441s 564ms/step - loss: 0.6940 - accuracy: 0.5082 - val_loss: 0.6935 - val_accuracy: 0.5062\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 442s 566ms/step - loss: 0.6892 - accuracy: 0.5098 - val_loss: 0.6953 - val_accuracy: 0.5049\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a115c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
