{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679505198628,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "NM9uKgKIS2eQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TextVectorization\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679505111248,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "RwEqSsR1ThAl"
   },
   "outputs": [],
   "source": [
    "# Define data \n",
    "#Define the training data as an array of strings (movie reviews) and their corresponding labels (0 for negative and 1 for positive).\n",
    "texts = [\n",
    "    \"This movie is amazing!\",\n",
    "    \"The acting was terrible and the plot was boring.\",\n",
    "    \"I loved everything about this movie!\",\n",
    "    \"The special effects were impressive but the story fell flat.\",\n",
    "    \"The dialogue was hilarious and the characters were engaging.\",\n",
    "    \"I couldn't even make it through this movie. It was that bad.\"\n",
    "]\n",
    "labels = np.array([1, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 983,
     "status": "ok",
     "timestamp": 1679505163646,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "C-BosUn8TkoK"
   },
   "outputs": [],
   "source": [
    "# Define TextVectorization layer\n",
    "#Define a TextVectorization layer that converts each string into a sequence of integers. \n",
    "#The layer is adapted to the training data so that it can learn the vocabulary of the dataset.\n",
    "\n",
    "max_len = 100 # Maximum sequence length to pad/crop sequences to\n",
    "vectorizer = TextVectorization(max_tokens=10000, output_mode='int', \n",
    "standardize='lower_and_strip_punctuation', split='whitespace', \n",
    "output_sequence_length=max_len)\n",
    "#max_tokens - specifies the maximum number of words to keep in the vocabulary.\n",
    "#output_mode parameter - set to 'int', means that the layer will output integer indices that correspond to the words in the vocabulary\n",
    "#output_sequence_length parameter- set to max_len, is the maximum length of each sequence of text data after padding or cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bjI4_bUV8q1"
   },
   "outputs": [],
   "source": [
    "#This step allows the layer to learn the vocabulary of the training data and configure its parameters accordingly.\n",
    "vectorizer.adapt(texts)\n",
    "\n",
    "# Vectorize input data\n",
    "X = vectorizer(texts)\n",
    "\n",
    "# Pad or crop the sequences to ensure they all have the same length using the pad_sequences function.\n",
    "X = pad_sequences(X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1679506993023,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "aWR1HsIeauNX",
    "outputId": "1c15b4ae-b62e-4cf9-a379-278396982d58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5, 18, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 2, 34,  3, 12,  9,  2, 15,  3, 31,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 8, 17, 23, 35,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 2, 14, 26,  6, 19, 30,  2, 13, 22, 21,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 2, 27,  3, 20,  9,  2, 29,  6, 25,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0],\n",
       "       [ 8, 28, 24, 16,  7, 10,  4,  5,  7,  3, 11, 32,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1679506983290,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "W6K-LgKhaj-C",
    "outputId": "d213e48d-5f2c-436a-88da-e4d44a7fd870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFfCMurMWtAK"
   },
   "source": [
    "vectorizer.adapt(texts) method is called to fit the TextVectorization layer to the training data (texts). This method computes the vocabulary of the text data and determines the length of the output sequence based on the output_sequence_length parameter. This step is necessary to ensure that the layer can handle variable-length inputs during inference. <br>\n",
    "\n",
    "After adapting the layer to the training data, the X = vectorizer(texts) line is used to vectorize the text data into a tensor of integer values. Each review is converted into a sequence of integers, where each integer represents a word in the vocabulary. The resulting tensor has shape (num_samples, sequence_length) where num_samples is the number of samples (in this case, the number of movie reviews) and sequence_length is the length of the output sequences (which is max_len in this code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1679505210535,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "OCMPeMusTnnY"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(max_len,)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1679505227254,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "Gr8OeuosT-dK",
    "outputId": "92eb08af-2093-4d34-83c7-cf694952730d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 906ms/step - loss: 1.3903 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a89180520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X, labels, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1679505233927,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "C5PKDLXDSxFP",
    "outputId": "f2df11fa-e99b-4653-8bc1-8b9c5db1681a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 296ms/step - loss: 1.0210 - accuracy: 0.5000\n",
      "Test set accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on new data\n",
    "new_texts = [\n",
    "    \"I was blown away by this movie!\",\n",
    "    \"I wouldn't recommend this movie to anyone.\"\n",
    "]\n",
    "new_labels = np.array([1, 0])\n",
    "new_X = vectorizer(new_texts)\n",
    "new_X = pad_sequences(new_X, maxlen=max_len)\n",
    "loss, accuracy = model.evaluate(new_X, new_labels)\n",
    "print(\"Test set accuracy: {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tN0ihUXMUBSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j020ViHXcjIG"
   },
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1679508855885,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "tPpwyfoTdHQH"
   },
   "outputs": [],
   "source": [
    "# Define custom functions for standardizing and splitting text\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data) #tf.strings is a module in the TensorFlow library that provides a collection of operations for working with strings in TensorFlow.\n",
    "    return tf.strings.regex_replace(lowercase, '[^a-zA-Z0-9]', ' ') # replace any character that is not a letter or a digit with a space character\n",
    "\n",
    "def custom_splitting(input_data):\n",
    "    return tf.strings.split(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1679508875750,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "FmTEHZEZh5Pq"
   },
   "outputs": [],
   "source": [
    "# Define data\n",
    "texts = [\n",
    "    \"This movie is amazing!\",\n",
    "    \"The acting was terrible and the plot was boring.\",\n",
    "    \"I loved everything about this movie!\",\n",
    "    \"The special effects were impressive but the story fell flat.\",\n",
    "    \"The dialogue was hilarious and the characters were engaging.\",\n",
    "    \"I couldn't even make it through this movie. It was that bad.\"\n",
    "]\n",
    "labels = tf.constant([1, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1679508891474,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "6AqaVtcSh7SV"
   },
   "outputs": [],
   "source": [
    "# Define TextVectorization layer with custom functions\n",
    "max_len = 100\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=10000,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_len,\n",
    "    standardize=custom_standardization,\n",
    "    split=custom_splitting\n",
    ")\n",
    "\n",
    "# Adapt the TextVectorization layer to the training data\n",
    "vectorizer.adapt(texts)\n",
    "\n",
    "# Vectorize the input data\n",
    "X = vectorizer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1679508935447,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "yGqPsEv9iGpK"
   },
   "outputs": [],
   "source": [
    "# Pad/crop sequences to ensure they all have the same length\n",
    "X = pad_sequences(X, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1679508953305,
     "user": {
      "displayName": "kruttika sutrave",
      "userId": "09962989647627185108"
     },
     "user_tz": 300
    },
    "id": "-9jIFPJhclf4",
    "outputId": "408820b7-af9a-45ab-ced3-da9b684796ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'was', 'this', 'movie', 'were', 'it', 'i', 'and', 'through', 'that', 'terrible', 't', 'story', 'special', 'plot', 'make', 'loved', 'is', 'impressive', 'hilarious', 'flat', 'fell', 'everything', 'even', 'engaging', 'effects', 'dialogue', 'couldn', 'characters', 'but', 'boring', 'bad', 'amazing', 'acting', 'about']\n",
      "[ 4  5 19 34  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# Print the vocabulary\n",
    "vocabulary = vectorizer.get_vocabulary()\n",
    "print(vocabulary)\n",
    "\n",
    "# Print the first example after vectorization\n",
    "print(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vxFVeUNiNct"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO0l/saCO0jjClK+tbjHLnA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
