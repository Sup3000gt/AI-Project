{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9CMQTl8Vz4X",
    "outputId": "46aefba2-3fc5-45f1-9348-2f4852523b83"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4880\\1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wISsMYJfPqI_"
   },
   "source": [
    "Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ip3B4-s9w4E"
   },
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOHR2qHK92QP"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aKBs1BdnVHl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential #The Sequential class in Keras is used to build sequential models, which are a linear stack of layers.\n",
    "from keras.layers import Dense #Dense class in Keras is used to add a fully connected layer to a neural network. It is a layer where each neuron in the layer is connected to every neuron in the previous layer.\n",
    "from sklearn.model_selection import train_test_split #\"train_test_split\" function in scikit-learn is used to split a dataset into training and testing subsets.\n",
    "from sklearn.preprocessing import StandardScaler #\"StandardScaler\" class in scikit-learn is used for standardizing numerical features in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4UIXTkOPs2D"
   },
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ydvP2TlndQq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the wine quality dataset\n",
    "wine_data = pd.read_csv('drive/My Drive/CSC 547/red-wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkQjiQytTx5h"
   },
   "source": [
    "TODO: Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T_pSB3-sWQKS",
    "outputId": "8be18d53-4354-4422-dfa5-bf54c7b87bfd"
   },
   "outputs": [],
   "source": [
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFygGkTEP0WT"
   },
   "source": [
    "Preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMZ_dmfFytNO"
   },
   "outputs": [],
   "source": [
    "wine_data['quality'] = wine_data.quality.apply(lambda q: 0 if q <= 5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXTN5CCXnd7G"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into input features (X) and output (y)\n",
    "X = wine_data.drop('quality', axis=1)\n",
    "y = wine_data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faxxaUfjngFv"
   },
   "outputs": [],
   "source": [
    "# Normalize the input features\n",
    "scaler = StandardScaler() #scaler is an instance of the \"StandardScaler\" class\n",
    "X = scaler.fit_transform(X) #fit_transform method is used to compute the mean and standard deviation of each feature in X, and then transform X. resulting X matrix has zero mean and unit variance for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PQPkrU_nFOU"
   },
   "source": [
    "Standardization is a common preprocessing technique in machine learning that scales the values of each feature so that they have a mean of 0 and a standard deviation of 1. This is often desirable because many machine learning algorithms assume that the features are normally distributed and have the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-1KuJ-KnimM"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "#train_test_split function randomly splits the dataset into training and testing subsets  \n",
    "#test_size parameter which is set to 0.2 in this case, indicating that 20% of the data will be used for testing\n",
    "#random_state parameter is set to 42 to ensure that the random splitting is reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEyOW83aeASf",
    "outputId": "8ce6570d-5ebc-4eb4-fbf4-fbc1ee12b53c"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKq8hQ07P9t4"
   },
   "source": [
    "Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2an8RcxonmnG"
   },
   "outputs": [],
   "source": [
    "# Create the Keras model\n",
    "model = Sequential() #Sequential() function creates an empty model that can be modified by adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ohkVw9XgUs4"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu')) #add() method is used to add layers to the model\n",
    "#64, specifies the number of neurons in the layer\n",
    "#input_dim=X_train.shape[1], sets the input shape of the layer to the number of features in the training set\n",
    "#activation='relu', specifies the activation function to be used in the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_3iAgpGgVpL"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) #output of this layer will be a probability between 0 and 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFS89WrRQBC8"
   },
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yZwOvxmnpvE"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#loss='binary_crossentropy' - specifies the loss function to be used during training. Binary cross-entropy is a common loss function used for binary classification problems.\n",
    "#optimizer='adam' - specifies the optimization algorithm. \n",
    "#metrics=['accuracy'] - specifies the evaluation metric to be used during training and testing. Accuracy is the ratio of the number of correct predictions to the total number of predictions made by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9nmHW8gQf6u"
   },
   "source": [
    "Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIboIzWPnwCR",
    "outputId": "fee34cdf-2a1d-4bf3-c6f8-09815581af98"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "#fit method trains the model for a fixed number of epochs. In this case, model is trained for 50 epochs.\n",
    "#batch_size=32 - the number of samples to be used in each batch during training. typically set as a power of 2, such as 32, 64, or 128\n",
    "#history - contains information about the training process such as the loss and accuracy metrics for both the training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84NgufoSlwvg"
   },
   "source": [
    "**iteration size** = (number of training examples) / (batch size) = 1279 / 32 = 39.97\n",
    "iteration size refers to the number of passes through the entire training dataset that are needed to complete one epoch of training. <br>\n",
    "Iteration size is not an integer in this case, so round up to the nearest integer. The iteration size in this case would be 40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2FdZ226Qp7h"
   },
   "source": [
    "Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn04Pg-JQq5T",
    "outputId": "a5b55c46-d506-4232-d0f0-f599b8ef5894"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "#evaluate method computes the loss value and any other specified metrics for the test data\n",
    "#score will contain the computed loss value and the accuracy metric for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uax0S3s-jpZo",
    "outputId": "45462d5c-e585-4ecd-a6c0-9ff37c14ccf6"
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjw5Adk2Qzrd"
   },
   "source": [
    "Visualize Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2H4pOn_crVk"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "zFG-6Ypscr7q",
    "outputId": "67eac0a8-ede6-4fd2-ca9a-4e07c32a2459"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy over epochs\n",
    "plt.plot(history.history['accuracy']) #plt.plot() is a function used to create a line plot of two or more arrays of data\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Ne5g4aG_cvWX",
    "outputId": "5f2c12e3-bb85-46ea-d7ea-b39e679e8f9c"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss over epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ohWxutEbj8IA",
    "outputId": "9998c394-f83a-44d3-c3af-ee9415964b1f"
   },
   "outputs": [],
   "source": [
    "#example of plot function\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [1, 4, 9, 16, 25]\n",
    "\n",
    "a = [2, 4, 6, 8, 10]\n",
    "b = [1, 4, 9, 16, 25]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(a,b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aqdz-TNUkcKY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
