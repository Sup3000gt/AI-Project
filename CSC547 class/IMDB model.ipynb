{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61db1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TextVectorization\n",
    "from keras.utils import pad_sequences\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd541bc5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b2c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\\\Users\\\\alan\\\\AI Project\\\\dataset\\\\aclImdb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caaa8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['0','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8275c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reviews(path):\n",
    "  data = []\n",
    "  #path = 'aclImdb/train/pos/'\n",
    "  files = [f for f in os.listdir(path)]\n",
    "  for file in files:\n",
    "    with open(path+file, \"r\", encoding='utf8') as f:\n",
    "      data.append(f.read())\n",
    "      \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c45cb22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews in df:  (50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
       "1  Homelessness (or Houselessness as George Carli...      1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
       "3  This is easily the most underrated film inn th...      1\n",
       "4  This is not the typical Mel Brooks film. It wa...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pos = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\train\\\\pos\\\\\"), 'label': 1})\n",
    "df_train_neg = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\train\\\\neg\\\\\"), 'label': 0})\n",
    "\n",
    "df_test_pos = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\test\\\\pos\\\\\"), 'label': 1})\n",
    "df_test_neg = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\test\\\\neg\\\\\"), 'label': 0})\n",
    "\n",
    "# Merging all df's for data cleaning and preprocessing step.\n",
    "df = pd.concat([df_train_pos, df_train_neg, df_test_pos, df_test_neg], ignore_index=True)\n",
    "print(\"Total reviews in df: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1300c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of positive reviews in data:  25000\n",
      "Total Number of negative reviews in data:  25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of positive reviews in data: \", df[df['label']==1].shape[0])\n",
    "print(\"Total Number of negative reviews in data: \", df[df['label']==0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e6bb2",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bfaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff3eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining stop_words\n",
    "stop_words = stopwords.words('english') \n",
    "\n",
    "# removing not from the stop_words list as it contains value in negative movies\n",
    "stop_words.remove('not') \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5fafbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(review):\n",
    "    \n",
    "  # data cleaning\n",
    "  review = re.sub(re.compile('<.*?>'), '', review) #removing html tags\n",
    "  review =  re.sub('[^A-Za-z0-9]+', ' ', review) #taking only words\n",
    "  \n",
    "  # lowercase\n",
    "  review = review.lower()\n",
    "  \n",
    "  # tokenization\n",
    "  tokens = nltk.word_tokenize(review) # converts review to tokens\n",
    "  \n",
    "  # stop_words removal\n",
    "  review = [word for word in tokens if word not in stop_words] #removing stop words\n",
    "  \n",
    "  # lemmatization\n",
    "  review = [lemmatizer.lemmatize(word) for word in review]\n",
    "  \n",
    "  # join words in preprocessed review\n",
    "  review = ' '.join(review)\n",
    "  \n",
    "  return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "066d0948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "      <td>bromwell high cartoon comedy ran time program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "      <td>homelessness houselessness george carlin state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "      <td>brilliant acting lesley ann warren best dramat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "      <td>easily underrated film inn brook cannon sure f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>not typical mel brook film much le slapstick m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      1   \n",
       "1  Homelessness (or Houselessness as George Carli...      1   \n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...      1   \n",
       "3  This is easily the most underrated film inn th...      1   \n",
       "4  This is not the typical Mel Brooks film. It wa...      1   \n",
       "\n",
       "                                 preprocessed_review  \n",
       "0  bromwell high cartoon comedy ran time program ...  \n",
       "1  homelessness houselessness george carlin state...  \n",
       "2  brilliant acting lesley ann warren best dramat...  \n",
       "3  easily underrated film inn brook cannon sure f...  \n",
       "4  not typical mel brook film much le slapstick m...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_review'] = df['review'].apply(lambda review: data_preprocessing(review))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8012b",
   "metadata": {},
   "source": [
    "### Splitting data(70-30): Train | Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48fd6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (35000, 2) (35000,)\n",
      "Test data: (15000, 2) (15000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.copy()\n",
    "y = data['label'].values\n",
    "data.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3, stratify=y)\n",
    "\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f00b",
   "metadata": {},
   "source": [
    "## Vectorizing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51490022",
   "metadata": {},
   "source": [
    "### Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e151c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_review_bow shape:  (35000, 19507)\n",
      "X_test_review_bow shape:  (15000, 19507)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(min_df=10)\n",
    "\n",
    "X_train_review_bow = vect.fit_transform(X_train['preprocessed_review'])\n",
    "X_test_review_bow = vect.transform(X_test['preprocessed_review'])\n",
    "\n",
    "print('X_train_review_bow shape: ', X_train_review_bow.shape)\n",
    "print('X_test_review_bow shape: ', X_test_review_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d3f8d",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225c778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_review_tfidf shape:  (35000, 19507)\n",
      "X_test_review_tfidf shape:  (15000, 19507)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "\n",
    "X_train_review_tfidf = vectorizer.fit_transform(X_train['preprocessed_review'])\n",
    "X_test_review_tfidf = vectorizer.transform(X_test['preprocessed_review'])\n",
    "\n",
    "print('X_train_review_tfidf shape: ', X_train_review_tfidf.shape)\n",
    "print('X_test_review_tfidf shape: ', X_test_review_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3285a0",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cd9dc37",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2798844281.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\alan\\AppData\\Local\\Temp\\ipykernel_34388\\2798844281.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    model.add(layers.Dense(25, activation = \"relu\")\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "\n",
    "# Input - Layer\n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "model.add(layers.Dense(25, activation = \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65dee1cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got multiple values for argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34388\\2423914998.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_review_bow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_review_bow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got multiple values for argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "# Output- Layer\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))model.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1abe10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9642872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
