{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "61db1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TextVectorization\n",
    "from keras.utils import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd541bc5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e1b2c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\\\Users\\\\alan\\\\AI Project\\\\dataset\\\\aclImdb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8275c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reviews(path):\n",
    "  data = []\n",
    "  #path = 'aclImdb/train/pos/'\n",
    "  files = [f for f in os.listdir(path)]\n",
    "  for file in files:\n",
    "    with open(path+file, \"r\", encoding='utf8') as f:\n",
    "      data.append(f.read())\n",
    "      \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c45cb22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews in df:  (50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
       "1  Homelessness (or Houselessness as George Carli...      1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
       "3  This is easily the most underrated film inn th...      1\n",
       "4  This is not the typical Mel Brooks film. It wa...      1"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pos = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\train\\\\pos\\\\\"), 'label': 1})\n",
    "df_train_neg = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\train\\\\neg\\\\\"), 'label': 0})\n",
    "\n",
    "df_test_pos = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\test\\\\pos\\\\\"), 'label': 1})\n",
    "df_test_neg = pd.DataFrame({'review': fetch_reviews(data_dir+\"\\\\test\\\\neg\\\\\"), 'label': 0})\n",
    "\n",
    "# Merging all df's for data cleaning and preprocessing step.\n",
    "df = pd.concat([df_train_pos, df_train_neg, df_test_pos, df_test_neg], ignore_index=True)\n",
    "print(\"Total reviews in df: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e0d353fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No null values in dataset.\n",
    "df['review'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1c1300c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of positive reviews in data:  25000\n",
      "Total Number of negative reviews in data:  25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of positive reviews in data: \", df[df['label']==1].shape[0])\n",
    "print(\"Total Number of negative reviews in data: \", df[df['label']==0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e6bb2",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d3bfaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4ff3eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') # defining stop_words\n",
    "stop_words.remove('not') # removing not from the stop_words list as it contains value in negative movies\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b5fafbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(review):\n",
    "    \n",
    "  # data cleaning\n",
    "  review = re.sub(re.compile('<.*?>'), '', review) #removing html tags\n",
    "  review =  re.sub('[^A-Za-z0-9]+', ' ', review) #taking only words\n",
    "  \n",
    "  # lowercase\n",
    "  review = review.lower()\n",
    "  \n",
    "  # tokenization\n",
    "  tokens = nltk.word_tokenize(review) # converts review to tokens\n",
    "  \n",
    "  # stop_words removal\n",
    "  review = [word for word in tokens if word not in stop_words] #removing stop words\n",
    "  \n",
    "  # lemmatization\n",
    "  review = [lemmatizer.lemmatize(word) for word in review]\n",
    "  \n",
    "  # join words in preprocessed review\n",
    "  review = ' '.join(review)\n",
    "  \n",
    "  return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "066d0948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "      <td>bromwell high cartoon comedy ran time program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "      <td>homelessness houselessness george carlin state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "      <td>brilliant acting lesley ann warren best dramat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "      <td>easily underrated film inn brook cannon sure f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>not typical mel brook film much le slapstick m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      1   \n",
       "1  Homelessness (or Houselessness as George Carli...      1   \n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...      1   \n",
       "3  This is easily the most underrated film inn th...      1   \n",
       "4  This is not the typical Mel Brooks film. It wa...      1   \n",
       "\n",
       "                                 preprocessed_review  \n",
       "0  bromwell high cartoon comedy ran time program ...  \n",
       "1  homelessness houselessness george carlin state...  \n",
       "2  brilliant acting lesley ann warren best dramat...  \n",
       "3  easily underrated film inn brook cannon sure f...  \n",
       "4  not typical mel brook film much le slapstick m...  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_review'] = df['review'].apply(lambda review: data_preprocessing(review))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8012b",
   "metadata": {},
   "source": [
    "### Splitting data(70-30): Train | Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "48fd6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (35000, 2) (35000,)\n",
      "Test data: (15000, 2) (15000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.copy()\n",
    "y = data['label'].values\n",
    "data.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3, stratify=y)\n",
    "\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f00b",
   "metadata": {},
   "source": [
    "## Vectorizing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51490022",
   "metadata": {},
   "source": [
    "### Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e151c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_review_bow shape:  (35000, 19577)\n",
      "X_test_review_bow shape:  (15000, 19577)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(min_df=10)\n",
    "\n",
    "X_train_review_bow = vect.fit_transform(X_train['preprocessed_review'])\n",
    "X_test_review_bow = vect.transform(X_test['preprocessed_review'])\n",
    "\n",
    "print('X_train_review_bow shape: ', X_train_review_bow.shape)\n",
    "print('X_test_review_bow shape: ', X_test_review_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d3f8d",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "225c778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_review_tfidf shape:  (35000, 19577)\n",
      "X_test_review_tfidf shape:  (15000, 19577)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "\n",
    "X_train_review_tfidf = vectorizer.fit_transform(X_train['preprocessed_review'])\n",
    "X_test_review_tfidf = vectorizer.transform(X_test['preprocessed_review'])\n",
    "\n",
    "print('X_train_review_tfidf shape: ', X_train_review_tfidf.shape)\n",
    "print('X_test_review_tfidf shape: ', X_test_review_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3285a0",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b58b02",
   "metadata": {},
   "source": [
    "#### Naive Bayes: BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "82944858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_review_bow, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_review_bow) #prediction from model\n",
    "print('Test Accuracy: ', accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d64a69",
   "metadata": {},
   "source": [
    "#### Naive Bayes: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "15a4fe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8602666666666666\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(X_train_review_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_review_tfidf)\n",
    "print('Test Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a8437d",
   "metadata": {},
   "source": [
    "#### Logistic Regression: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0b050af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "33f8e182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8897333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "clf.fit(X_train_review_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_review_tfidf)\n",
    "print('Test Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8fcd7970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+----------+\n",
      "| Vectorizer |        Model        | Accuracy |\n",
      "+------------+---------------------+----------+\n",
      "|    BOW     |     Naive Bayes     |  84.6%   |\n",
      "|   TFIDF    |     Naive Bayes     |  85.3%   |\n",
      "|   TFIDF    | Logistic Regression |  88.0%   |\n",
      "+------------+---------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = ['Vectorizer', 'Model', 'Accuracy']\n",
    "x.add_row(['BOW', 'Naive Bayes', '84.6%'])\n",
    "x.add_row(['TFIDF', 'Naive Bayes', '85.3%'])\n",
    "x.add_row(['TFIDF', 'Logistic Regression', '88.0%'])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dee1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
