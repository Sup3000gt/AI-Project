{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc17562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d425f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"positive text\",\"negative text\",\"positive review\",\"negative review\"]\n",
    "labels = [1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bfcf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text vectorization layer\n",
    "max_tokens = 100\n",
    "text_vectorization = layers.TextVectorization(max_tokens=max_tokens)\n",
    "text_vectorization.adapt(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d8a3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the unzipped file\n",
    "path_to_glove_file = \"C:\\\\Users\\\\xinga\\\\OneDrive\\\\文档\\\\GitHub\\\\AI-Project\\\\dataset\\\\glove\\\\glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e35c75ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1) #it split the line into two parts, first part is word, second part is\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \") # convert the vector from a string to a numpy array of floating point\n",
    "        embeddings_index[word] = coefs # adds the word asnd its corresponding vector to the \"embedding\"\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "353b3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['', '[UNK]', 'text', 'review', 'positive', 'negative']\n",
      "{'': 0, '[UNK]': 1, 'text': 2, 'review': 3, 'positive': 4, 'negative': 5}\n"
     ]
    }
   ],
   "source": [
    "# build an embedding matrix that you can load into an Embedding layer\n",
    "embedding_dim = 100\n",
    "vocabulary = text_vectorization.get_vocabulary() # retrieve the vocabulary indexed by our \n",
    "print(len(vocabulary))\n",
    "print(vocabulary)\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary)))) # use it to create a mapping from word\n",
    "print(word_index)\n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c4e3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i < max_tokens:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0fd09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(\n",
    "    max_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix), \n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a8a3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None,),dtype=\"int64\")\n",
    "embedded = embedding_layer(inputs)\n",
    "x = layers.LSTM(32)(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2ce83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d654ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5936 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6839 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5752 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6031 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5997 - accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4980 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5892 - accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5180 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22153ea32e0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(text_vectorization(texts),np.array(labels),batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67d3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccc85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
