{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6050e8f4",
   "metadata": {},
   "source": [
    "1. Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e755f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, concatenate\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import boston_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738bbfba",
   "metadata": {},
   "source": [
    "2. load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d160eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "common method for data clean\n",
    "dropna(): DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "fillna(): DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n",
    "replace(): DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
    "duplicated(): DataFrame.duplicated(subset=None, keep='first')\n",
    "drop_duplicates(): DataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
    "str.strip(): Series.str.strip(to_strip=None)\n",
    "str.lower(): Series.str.lower()\n",
    "str.upper(): Series.str.upper()\n",
    "rename(): DataFrame.rename(mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors='raise')\n",
    "astype(): DataFrame.astype(dtype, copy=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac04137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 1, load from local file\n",
    "wine_data = pd.read_csv(\"C:/Users/xinga/OneDrive/文档/GitHub/AI-Project/dataset/red-wine.csv\")\n",
    "\n",
    "# example 2, build in from library database\n",
    "housing_data = fetch_california_housing()\n",
    "a = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into features X and Y\n",
    "# wine\n",
    "wine_data['quality'] = wine_data.quality.apply(lambda q:0 if q <=5 else 1)\n",
    "x = wine_data.drop('quality',axis=1)\n",
    "y = wine_data['quality']\n",
    "\n",
    "# California housing\n",
    "X = housing_data.data\n",
    "Y = housing_data.target\n",
    "\n",
    "# Boston housing\n",
    "X = train_data\n",
    "Y = test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e875a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input feature (if necessary)\n",
    "\n",
    "# wine example\n",
    "scaler = StandardScaler()   # scaler is an instance of the \"StandardScaler\" class\n",
    "X = scaler.fit_transform(x) # this method is used to compute the mean and standard deviation of X and Y\n",
    "\n",
    "# boston example\n",
    "scaler = StandardScaler().fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733b0047",
   "metadata": {},
   "source": [
    "3. split the data into, train, test and (validation) if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12436424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)\n",
    "# train_test_split randomly split the data into 2 parts\n",
    "# 0.2 = 20% of data will be used in test\n",
    "# random_state parameter is set to 42 to ensure that the random splitting is reproducible, commonly use 42 or 0\n",
    "\n",
    "# California housing\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Boston housing\n",
    "(train_data,train_targets),(test_data,test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbac7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n",
    "\n",
    "# wine\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# California \n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if result is not binary\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7ca93",
   "metadata": {},
   "source": [
    "4. create the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = x_train.shape[1],activation = 'relu'))\n",
    "# 64, specifies the number of neurons in the layer\n",
    "#add method is use to add layer to the model\n",
    "# input_dim = x_train.shape[1], set the input shape of the layer to the number of features in the train\n",
    "# activation = 'relu' ,specifies the activation function to be used in the layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))# output of this layer will be probability betweent 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0476b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(1)) # The model ends with a single unit and no activation. \n",
    "# it will be a linear layer because last layer is purely linear in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91698838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# California \n",
    "\n",
    "# define the input layers\n",
    "input_A = Input(shape=(6,))\n",
    "input_B = Input(shape=(2,))\n",
    "\n",
    "# define the hidden layers\n",
    "hidden_A = Dense(30, activation = 'relu')(input_A) # dense layer take A as input\n",
    "hidden_B = Dense(30, activation = 'relu')(input_B)\n",
    "\n",
    "# concatenate the output from the hidden layers\n",
    "concat = concatenate([hidden_A,hidden_B])\n",
    "\n",
    "# define the output layer\n",
    "output = Dense(1)(concat) # dense layer is connected to the output of the previous layer\n",
    "\n",
    "# define the model\n",
    "model = keras.Model(inputs=[input_A,input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eae4b7",
   "metadata": {},
   "source": [
    "#### Activation Functions 常用激活函数\n",
    "- Sigmoid\n",
    "    - 将输入映射到0到1之间的值，通常用于二分类问题。\n",
    "- Tanh\n",
    "    - 将输入映射到-1到1之间的值，可以用于二分类问题和回归问题。\n",
    "- ReLU\n",
    "    - 将负数的输入值截断为0，只保留正数的输入值。是目前使用最广泛的激活函数，因为它能够提高模型的训练速度和精度。\n",
    "- Leaky ReLU\n",
    "    - 是对ReLU函数的改进，当输入为负数时不再完全截断为0，而是乘以一个小的斜率。\n",
    "- SoftMax\n",
    "    - 将输入映射到0到1之间的概率分布，通常用于多分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327e168",
   "metadata": {},
   "source": [
    "#### Loss Functions \n",
    "- mean_squared_error：\n",
    "    - 均方误差，适用于回归问题。\n",
    "- mean_absolute_error：\n",
    "    - 平均绝对误差，适用于回归问题。\n",
    "- mean_absolute_percentage_error:\n",
    "    - 平均百分比误差，适用于回归问题。\n",
    "- binary_crossentropy：\n",
    "    - 二元交叉熵，适用于二分类问题。\n",
    "- categorical_crossentropy：\n",
    "    - 分类交叉熵，适用于多分类问题。\n",
    "- sparse_categorical_crossentropy：\n",
    "    - 稀疏分类交叉熵，适用于多分类问题。\n",
    "- hinge：\n",
    "    - hinge损失函数，适用于支持向量机分类问题。\n",
    "- squared_hinge：\n",
    "    - 平方hinge损失函数，适用于支持向量机分类问题。\n",
    "- kullback_leibler_divergence：\n",
    "    - KL散度，适用于概率分布问题。\n",
    "- poisson：\n",
    "    - 泊松损失函数，适用于计数问题。\n",
    "- cosine_similarity：\n",
    "    - 余弦相似度，适用于相似度计算问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083ed19",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "- SGD(Stochastic Gradient Descent)\n",
    "- Adam：Adaptive Moment Estimation\n",
    "- RMSprop：Root Mean Square Propagation\n",
    "- Adagrad：Adaptive Gradient Algorithm\n",
    "- Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942492e",
   "metadata": {},
   "source": [
    "5. Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine \n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#loss-- specifies the loss function to be used during training.\n",
    "#optimizer - specifies the optimization algorithm\n",
    "# metrics - specifies the evaluation metric to be used durning training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# California \n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss = 'mse', metrics=['mae']) #MAE = mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston\n",
    "\n",
    "model.compile(optimizer='adam', loss = 'mse', metrics=['mae']) #MAE = mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# california but practice mid term\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e699f1",
   "metadata": {},
   "source": [
    "6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine\n",
    "history = model.fit(x_train,y_train,epochs=10, batch_size=64, validation_data=(x_test,y_test))\n",
    "#fit method trains the model for a fixed number of epochs.\n",
    "#batch = 32 - number of samples to be used in each batch durning training. usually set as power of 2\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1cdc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# California \n",
    "final_result = model.fit([X_train[:, :6], X_train[:, 6:]],Y_train, \n",
    "                         validation_data = ([X_valid[:, :6], X_valid[:, 6:]],Y_valid), epochs= 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston\n",
    "final_result = model.fit(train_data, train_targets, epochs= 50, batch_size = 32, validation_data = (test_data,test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice mid term\n",
    "result = model.fit(X_train, Y_train, epochs=20, batch_size=16, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd35ec3",
   "metadata": {},
   "source": [
    "iteration size =  training example / batch size  = 1279/32 =39.97 round to 40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a02f94",
   "metadata": {},
   "source": [
    "7. Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a968c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# California \n",
    "mse, mae = model.evaluate([X_test[:,:6],X_test[:,6:]],Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f84a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston\n",
    "mse_nn,mae_nn = model.evaluate(test_data,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102db557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553ba33",
   "metadata": {},
   "source": [
    "8. predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c7735",
   "metadata": {},
   "source": [
    "9. Visualize Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c53785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy over epochs\n",
    "plt.plot(final_result.history['mae']) #plt.plot() is a function used to create a line plot of two or more arrays of data\n",
    "plt.plot(final_result.history['val_mae'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb284bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss over epochs\n",
    "plt.plot(final_result.history['loss'])\n",
    "plt.plot(final_result.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('val_mae')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6658a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4a4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783d54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fef9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
